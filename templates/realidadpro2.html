<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Detección AI</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
            background: linear-gradient(-45deg, #cccccc, #0077cc, #0099ff, #0077cc);
            background-size: 200% 200%;
            animation: gradient 10s ease infinite;
        }
        @keyframes gradient {
            0% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
            100% { background-position: 0% 50%; }
        }
        #video-container {
            position: relative;
            width: 90%;
            max-width: 640px;
            display: flex;
            justify-content: center;
            align-items: center;
            margin: 10px auto;
            border: 2px solid black;
            background-color: #000;
        }
        #video, #canvas {
            width: 100%;
            display: block;
        }
        #canvas {
            position: absolute;
            top: 0;
            left: 0;
        }
        #detections-log {
            width: 90%;
            max-width: 300px;
            max-height: 500px;
            overflow-y: auto;
            border: 2px solid black;
            padding: 10px;
            background-color: #f9f9f9;
            margin-top: 20px;
        }
        .buttons-container {
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 10px;
            width: 100%;
            margin-top: 20px;
        }
        button {
            background-color: rgba(0, 122, 204, 0.8);
            color: white;
            padding: 10px;
            font-size: 16px;
            cursor: pointer;
            border-radius: 30px;
            border: none;
            text-transform: uppercase;
            transition: all 0.3s ease;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            width: 200px;
            text-align: center;
        }
        button:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 20px rgba(0, 0, 0, 0.2);
        }
        @media (max-width: 768px) {
            .buttons-container {
                flex-direction: column;
                align-items: center;
            }
            #detections-log {
                width: 100%;
            }
        }
    </style>
</head>
<body>
    <div id="video-container">
        <video id="video" autoplay></video>
        <canvas id="canvas"></canvas>
    </div>
    <div class="buttons-container">
        <button onclick="startDetection()">Start</button>
        <button onclick="stopDetection()">Stop</button>
        <button id="microphone-button">Talk</button>
    </div>
    <div id="detections-log">
        <h3>Detections</h3>
        <ul id="detections-list"></ul>
    </div>
</body>
    <script>
        const microphoneButton = document.getElementById("microphone-button");
        let detectionInterval;
        let detectedClasses = new Set(); // Guarda solo los nombres de las clases detectadas

        const params = new URLSearchParams(window.location.search);
        const domain = params.get("domain");

        async function sendFrameToBackend(frame) {
            const response = await fetch('/process_frame', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ image: frame, domain: domain })
            });
            const data = await response.json();
            drawBoundingBoxes(data.bounding_boxes);
            saveDetections(data.bounding_boxes);
        }

        function drawBoundingBoxes(boundingBoxes) {
            const canvas = document.getElementById('canvas');
            const video = document.getElementById('video');
            const ctx = canvas.getContext('2d');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            boundingBoxes.forEach(box => {
                ctx.beginPath();
                ctx.rect(box.x, box.y, box.width, box.height);
                ctx.strokeStyle = 'red';
                ctx.lineWidth = 3;
                ctx.stroke();
                ctx.font = '16px Arial';
                ctx.fillStyle = 'red';
                ctx.fillText(box.class_name, box.x, box.y - 10);
            });
        }
        function saveDetections(boundingBoxes) {
    let batchDetected = new Set(); // Guarda objetos únicos en el envío actual

    boundingBoxes.forEach(box => {
        if (!detectedClasses.has(box.class_name) || batchDetected.has(box.class_name)) { 
            detectedClasses.add(box.class_name); // Agregar al histórico
            batchDetected.add(box.class_name); // Agregar al batch del frame actual
            updateDetectionList(box.class_name);
        }
    });
}
        function updateDetectionList(objectName) {
            const ul = document.getElementById("detections-list");
            const li = document.createElement("li");
            li.textContent = objectName;
            ul.appendChild(li);
        }

        async function captureFrame() {
            const videoElement = document.getElementById('video');
            const canvas = document.createElement('canvas');
            canvas.width = videoElement.videoWidth;
            canvas.height = videoElement.videoHeight;
            canvas.getContext('2d').drawImage(videoElement, 0, 0);
            const image = canvas.toDataURL('image/jpeg');
            sendFrameToBackend(image);
        }

        function startDetection() {
    if (!detectionInterval) {
        startCamera()
        detectedClasses.clear();
        document.getElementById("detections-list").innerHTML = "";
        detectionInterval = setInterval(captureFrame, 2000);

    }
}

        function stopDetection() {
            if (detectionInterval) {
                clearInterval(detectionInterval);
                detectionInterval = null;
            }
            stopCamera(); // Ahora la cámara se apaga correctamente
            if (detectedClasses.size === 0) {
        alert("No hay detecciones para enviar.");
        return;
    }

    // Convertir los valores en objetos con el formato requerido
    let message = Array.from(detectedClasses).map(item => ({
        type: "text",
        text: item
    }));
    try {
        sendMessage(message)
            } catch (error) {
                alert("⚠️ Error en la solicitud.");
                console.error("⚠️ Error en la solicitud:", error);
            }
        }
        function sendMessage(userInput) {
        fetch('/chat', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({ message: userInput, model: domain }),
        })
        .then(response => response.json())
        .then(data => {
            speakResponse(data.text_response);
        })
    }
        function speakResponse(responseText) {
                fetch('/synthesize-audio', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ text: responseText, modelo: domain  }),
                })
                .then(audioResponse => {
                    if (audioResponse.ok) return audioResponse.blob();
                    throw new Error('Error al obtener el audio.');
                })
                .then(audioBlob => {
                    const audioUrl = URL.createObjectURL(audioBlob);
                    const audio = new Audio(audioUrl);
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const analyser = audioContext.createAnalyser();
                    const source = audioContext.createMediaElementSource(audio);
                    source.connect(analyser);
                    analyser.connect(audioContext.destination);

                    const dataArray = new Uint8Array(analyser.frequencyBinCount);


                    audio.onplay = function() {
                        isBotSpeaking = true;

                        if (recognition) recognition.stop(); 
                    };

                    audio.onended = function() {
                        isBotSpeaking = false;
                        if (isListening) recognition.start();
                    };

                    audio.play();
                })
                .catch(error => {
                    console.error('Error:', error);
                });
            }
            let recognition;
            let isListening = false;
                    let isBotSpeaking = false; // Variable para saber si el bot está hablando
                    function startVoiceRecognition() {
                if (!recognition) {
                    recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
                    recognition.lang = 'es-ES';
                    recognition.continuous = false;
                    recognition.interimResults = false;
                }

                recognition.onresult = function(event) {
                    if (!isBotSpeaking) { // Solo procesar si el bot no está hablando
                        const userInput = event.results[0][0].transcript;
                        sendMessage(userInput);
                    }
                };

                recognition.onerror = function(event) {
                    console.error("Error en el reconocimiento de voz: ", event.error);
                };

                recognition.onend = function() {
                    if (isListening && !isBotSpeaking) {
                        recognition.start(); // Reiniciar reconocimiento si sigue en modo escucha
                    }
                };

                recognition.start();

            }

            // Evento para iniciar o detener el reconocimiento de voz con el botón de 'Start Conversation'
            microphoneButton.onclick = function() {
                if (!isListening) {
                    isListening = true;
                    microphoneButton.innerText = "Stop Conversation";
                    startVoiceRecognition();
                } else {
                    isListening = false;
                    microphoneButton.innerText = "Start Conversation";
                    if (recognition) {
                        recognition.stop();
                    }

                }
            };
            let useBackCamera = true;
            let videoStream = null; // Se declara la variable globalmente

function startCamera() {
    const videoElement = document.getElementById('video');
    const constraints = {
        video: { facingMode: "environment" }
    };

    return navigator.mediaDevices.getUserMedia(constraints)
        .then(stream => {
            videoStream = stream; // Guardamos el stream en la variable global
            videoElement.srcObject = stream;
        })
        .catch(error => {
            console.error("Error al acceder a la cámara:", error);
        });
}

function stopCamera() {
    if (videoStream) {
        videoStream.getTracks().forEach(track => track.stop()); // Detiene la cámara
        videoStream = null; // Se limpia la variable
    }
    document.getElementById('video').srcObject = null; // Limpia el video
}

    </script>

</body>
</html>








