<!DOCTYPE html>
<html lang="es">
<head>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600&display=swap" rel="stylesheet">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/style.css') }}">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/toastr.js/latest/toastr.min.css" rel="stylesheet"/>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/toastr.js/latest/toastr.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jspdf/2.4.0/jspdf.umd.min.js"></script>

    <title>Chat with EverydAI</title>
</head>
<body>
    <button class ="redirect-button" onclick="redirectToRealidad()">Scan</button>
    <!-- Mostrar el modelo seleccionado dinámicamente -->
    <div id="selected-model-display" class="selected-model-display">
        {{ domain }}
    </div>
    
    <div id="recommendations-box" class="recommendations-box">
        <div class="header">
            <h3>Recommendations:</h3>
            <div id="toggle-arrow" class="arrow-container">
                <div class="arrow down"></div> <!-- Flecha personalizada -->
            </div>
        </div>
        <ul id="recommendations-list"></ul>
    </div>
    <script src="../static/java/recommendations.js"></script>

    <button id="download-button">Download Conversation</button>

    <div class="chat-container">
        <h1>Chat with EverydAI</h1>
        <div id="avatar-container" >
            <div id="subtitulos-container"> </div>
            <div class="dots" id="dots">
                <span></span>
                <span></span>
                <span></span>
              </div>
        </div>
        <div id="chat-box" class="hidden"></div>
        <input type="text" id="user-input" placeholder="Chat with us...">
        <button id="send-button">Send</button>
        
        <!-- Contenedor para controles, incluyendo el espectro de frecuencia -->
        <div class="control-container">
            <button id="microphone-button">Start Conversation</button>
            <input type="file" id="image-input" accept="image/*">
            <button id="upload-button">Upload Image</button>
            <button id="camera-button">Open Camera</button>
            <button id="capture-button" style="display:none;">Capture</button>
        </div>

        <!-- Canvas para el espectro de frecuencias -->
        <canvas id="frequency-canvas"></canvas>

        <video id="video-preview" autoplay style="display:none; width: 300px;"></video>
        <canvas id="canvas" style="display:none;"></canvas>

        <div id="image-preview-container" style="text-align: center;">
            <img id="image-preview" alt="Your uploaded image will appear here" style="display: none; width: 300px; margin-top: 10px;">
        </div>
    </div>

    <script>

        function redirectToRealidad() {
            window.location.href = "/realidadpro";
        }
        document.addEventListener("DOMContentLoaded", function() {
            const microphoneButton = document.getElementById("microphone-button");
            const frequencyCanvas = document.getElementById("frequency-canvas");
            const canvasContext = frequencyCanvas.getContext("2d");
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const imageInput = document.getElementById("image-input");
            const imagePreview = document.getElementById("image-preview");
            const videoPreview = document.getElementById("video-preview");
            const canvas = document.getElementById("canvas");
            const captureButton = document.getElementById("capture-button");
            let selectedModel = '{{ domain }}';
            let recognition;
            let analyser;
            let isListening = false;
            let isBotSpeaking = false; // Variable para saber si el bot está hablando

            // Función para iniciar el reconocimiento de voz y el espectro de frecuencias
            function startVoiceRecognition() {
                if (!recognition) {
                    recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
                    recognition.lang = 'es-ES';
                    recognition.continuous = false;
                    recognition.interimResults = false;
                }

                recognition.onresult = function(event) {
                    if (!isBotSpeaking) { // Solo procesar si el bot no está hablando
                        const userInput = event.results[0][0].transcript;
                        document.getElementById("user-input").value = userInput;
                        sendMessage(userInput);
                        dots.style.opacity = 1; // Mostrar los puntos
                        const event5 = new CustomEvent('pensar');
                        window.dispatchEvent(event5);
                    }
                };

                recognition.onerror = function(event) {
                    console.error("Error en el reconocimiento de voz: ", event.error);
                };

                recognition.onend = function() {
                    if (isListening && !isBotSpeaking) {
                        recognition.start(); // Reiniciar reconocimiento si sigue en modo escucha
                    }
                };

                recognition.start();
                startFrequencySpectrum(); // Iniciar el espectro de frecuencias
            }

            // Evento para iniciar o detener el reconocimiento de voz con el botón de 'Start Conversation'
            microphoneButton.onclick = function() {
                if (!isListening) {
                    isListening = true;
                    microphoneButton.innerText = "Stop Conversation";
                    startVoiceRecognition();
                } else {
                    isListening = false;
                    microphoneButton.innerText = "Start Conversation";
                    if (recognition) {
                        recognition.stop();
                    }
                    stopFrequencySpectrum();
                }
            };

            // Función para iniciar el espectro de frecuencias
            function startFrequencySpectrum() {
                navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {
                    const source = audioContext.createMediaStreamSource(stream);
                    analyser = audioContext.createAnalyser();
                    source.connect(analyser);
                    analyser.fftSize = 256;

                    frequencyCanvas.style.display = "block";
                    drawFrequencySpectrum();
                }).catch((error) => {
                    console.error("Error al acceder al micrófono: ", error);
                });
            }

            // Función para detener el espectro de frecuencias
            function stopFrequencySpectrum() {
                frequencyCanvas.style.display = "none";
            }

            // Función para dibujar el espectro de frecuencias
            function drawFrequencySpectrum() {
                if (!isListening) return;

                requestAnimationFrame(drawFrequencySpectrum);

                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                analyser.getByteFrequencyData(dataArray);

                canvasContext.clearRect(0, 0, frequencyCanvas.width, frequencyCanvas.height);
                const barWidth = (frequencyCanvas.width / bufferLength) * 2.5;
                let barHeight;
                let x = 0;

                for (let i = 0; i < bufferLength; i++) {
                    barHeight = dataArray[i] / 2;
                    canvasContext.fillStyle = `rgb(${barHeight + 100}, 50, 50)`;
                    canvasContext.fillRect(x, frequencyCanvas.height - barHeight, barWidth, barHeight);
                    x += barWidth + 1;
                }
            }

            // Función para enviar mensajes (tanto por texto como por voz)
           function sendMessage(userInput) {
    if (userInput.trim() !== "") {
        document.getElementById("chat-box").innerHTML += `<div>Usuario: ${userInput}</div>`;
        document.getElementById("user-input").value = ''; // Limpiar el input después de enviar

        // Detener temporalmente el reconocimiento de voz mientras se obtiene la respuesta del bot
        if (recognition) recognition.stop();
        isBotSpeaking = true;

        fetch('/chat', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({ message: userInput, model: selectedModel }),
        })
        .then(response => response.json())
        .then(data => {
            document.getElementById("chat-box").innerHTML += `<div>AI: ${data.text_response}</div>`;
            speakResponse(data.text_response);

            // Mostrar las recomendaciones en el cuadro de recomendaciones
            const recommendationsList = document.getElementById("recommendations-list");
            recommendationsList.innerHTML = '';  // Limpiar la lista existente

        // Verificar si data.recipes es un array antes de recorrerlo
        if (Array.isArray(data.recipes)) {
            data.recipes.forEach(item => {
                const listItem = document.createElement("li");

                // Verificamos si el objeto tiene las llaves 'nombre' y 'precio'
                if (item.nombre && item.precio) {
                    // Si tiene 'nombre' y 'precio', mostramos el producto
                    listItem.innerHTML = `<div class="producto">
                                            <span class="producto-nombre">${item.nombre}</span> - 
                                            <span class="producto-precio">${item.precio}</span>
                                        </div>`;

                    // Verificamos si también tiene la URL de la imagen
                    if (item.imagen_url) {
                        // Crear un elemento de imagen y asignarle la URL
                        const imgElement = document.createElement("img");
                        imgElement.src = item.imagen_url;
                        imgElement.alt = item.nombre;
                        imgElement.classList.add("producto-imagen");  // Añadir clase CSS

                        // Añadir la miniatura de la imagen al `listItem`
                        listItem.prepend(imgElement);  // Insertamos la imagen antes del texto
                    }

                    // Agregar una clase para dar estilo a los productos con nombre y precio
                    listItem.classList.add("producto-con-precio");
                } else if (item.link && item.title) {
                    // Si tiene 'link' y 'title', mostramos la receta
                    listItem.innerHTML = `<a href="${item.link}" target="_blank">${item.title}</a>`;
                } else {
                    // Si no tiene 'nombre' y 'precio' ni 'link' y 'title', mostramos un mensaje por defecto
                    listItem.innerHTML = "Información no válida";
                }

                // Añadir cada item a la lista de recomendaciones
                recommendationsList.appendChild(listItem);
            });
        } else {
            recommendationsList.innerHTML = '<li>No se encontraron recomendaciones.</li>';
        }


        })
        .catch(error => console.error('Error:', error));
    }
}

            // Función para sintetizar y reproducir el audio de la respuesta
            function speakResponse(responseText) {
                const subtitulosContainer = document.getElementById("subtitulos-container");
                if (!subtitulosContainer) {
                    console.error("El contenedor de subtítulos no existe.");
                    return;
                }
                    // Mostrar subtítulos
                //subtitulosContainer.textContent = responseText;
                //subtitulosContainer.style.display = "block";

                fetch('/synthesize-audio', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ text: responseText, modelo: selectedModel  }),
                })
                .then(audioResponse => {
                    if (audioResponse.ok) return audioResponse.blob();
                    throw new Error('Error al obtener el audio.');
                })
                .then(audioBlob => {
                    const audioUrl = URL.createObjectURL(audioBlob);
                    const audio = new Audio(audioUrl);
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const analyser = audioContext.createAnalyser();
                    const source = audioContext.createMediaElementSource(audio);
                    source.connect(analyser);
                    analyser.connect(audioContext.destination);

                    const dataArray = new Uint8Array(analyser.frequencyBinCount);

                    function emitAudioLevels() {
                        analyser.getByteFrequencyData(dataArray);
                        const avgAmplitude = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;

                        const event = new CustomEvent('audio-level', { detail: { amplitude: avgAmplitude / 255 } });
                        window.dispatchEvent(event);
                        if (!audio.paused && !audio.ended) {
                            requestAnimationFrame(emitAudioLevels);
                        }
                    }

                    audio.onplay = function() {
                        const event2 = new CustomEvent('hablar');
                        window.dispatchEvent(event2);
                        isBotSpeaking = true;
                        emitAudioLevels();
                        if (recognition) recognition.stop(); 
                        mostrarSubtitulosProgresivos(responseText, audio.duration, subtitulosContainer);
                    };

                    audio.onended = function() {
                        const event3 = new CustomEvent('parar');
                        window.dispatchEvent(event3);
                        isBotSpeaking = false;
                        if (isListening) recognition.start();
                        const event = new CustomEvent('audio-level', { detail: { amplitude: 0 } });
                        window.dispatchEvent(event);
                        subtitulosContainer.style.display = "none"; 
                    };

                    audio.play();
                })
                .catch(error => {
                    console.error('Error:', error);
                    subtitulosContainer.style.display = "none"; // Ocultar subtítulos en caso de error
                });
            }
            // Función para mostrar subtítulos progresivamente
            function mostrarSubtitulosProgresivos(textoCompleto, duracionAudio, contenedor) {
                const palabras = textoCompleto.split(" ");
                const tiempoPorPalabra = duracionAudio / palabras.length;

                contenedor.textContent = ""; // Limpia los subtítulos previos
                contenedor.style.display = "block";

                let indice = 0;

                const intervalo = setInterval(() => {
                    if (indice < palabras.length) {
                        contenedor.textContent += palabras[indice] + " "; // Añade palabra actual
                        indice++;
                    } else {
                        clearInterval(intervalo); // Detén el intervalo cuando terminen las palabras
                    }
                }, tiempoPorPalabra * 50001); // Convierte el tiempo por palabra a milisegundos
            }
            const dots = document.getElementById("dots");
            // Evento al hacer clic en el botón de enviar texto manualmente
            document.getElementById("send-button").onclick = function() {
    const userInput = document.getElementById("user-input").value.trim(); // Elimina espacios en blanco
    if (userInput) { // Si el input no está vacío
        sendMessage(userInput);
        
        // Cambiar la opacidad de los puntos
        const dots = document.getElementById("dots");
        const event3 = new CustomEvent('pensar');
        window.dispatchEvent(event3);
        dots.style.opacity = 1; // Mostrar los puntos
    } else {
        alert("Please enter a message before sending.");
    }
};
            // Funcionalidad para abrir la cámara
            document.getElementById("camera-button").onclick = function() {
                if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                    navigator.mediaDevices.getUserMedia({ video: true }).then(function(stream) {
                        videoPreview.srcObject = stream;
                        videoPreview.style.display = "block";
                        document.getElementById("capture-button").style.display = "block";
                    }).catch(function(error) {
                        console.error("Error al acceder a la cámara: ", error);
                    });
                }
            };

            // Funcionalidad para capturar imagen de la cámara
            captureButton.onclick = function() {
                const context = canvas.getContext('2d');
                canvas.width = videoPreview.videoWidth;
                canvas.height = videoPreview.videoHeight;
                context.drawImage(videoPreview, 0, 0);
                const imageData = canvas.toDataURL('image/png');
                imagePreview.src = imageData;
                imagePreview.style.display = "block";

                // Detener el stream de video
                const stream = videoPreview.srcObject;
                const tracks = stream.getTracks();
                tracks.forEach(track => track.stop());
                videoPreview.srcObject = null;
                videoPreview.style.display = "none";
                captureButton.style.display = "none";

                // Enviar la imagen capturada al servidor
                canvas.toBlob(function(blob) {
                    const formData = new FormData();
                    formData.append('image', blob, 'captured-image.png');
                    formData.append('model', selectedModel);

                    fetch('/upload-image', {
                        method: 'POST',
                        body: formData,
                    })
                    .then(response => response.json())
                    .then(data => {
                        // Muestra la alerta SweetAlert2
                        Swal.fire({
                            title: 'Success!',
                            text: 'Image uploaded successfully',
                            icon: 'success',
                            confirmButtonText: 'OK'
                        });

                        document.getElementById("chat-box").innerHTML += `<div>Modelo: ${data.response}</div>`;
                        speakResponse(data.response);
                    })
                    .catch(error => console.error('Error:', error));
                }, 'image/png');
            };

            // Evento al hacer clic en el botón de cargar imagen
            document.getElementById("upload-button").onclick = function() {
                const file = imageInput.files[0];

                if (file) {
                    const formData = new FormData();
                    formData.append('image', file);
                    formData.append('model', selectedModel);
                    dots.style.opacity = 1; // Mostrar los puntos
                    const event4 = new CustomEvent('pensar');
                    window.dispatchEvent(event4);
                    fetch('/upload-image', {
                        method: 'POST',
                        body: formData,
                    })
                    .then(response => response.json())
                    .then(data => {
                            // Muestra la alerta SweetAlert2
                            Swal.fire({
                            title: 'Success!',
                            text: 'Image uploaded successfully',
                            icon: 'success',
                            confirmButtonText: 'OK'
                        });

                        document.getElementById("chat-box").innerHTML += `<div>Modelo: ${data.response}</div>`;
                        speakResponse(data.response);
                    })
                    .catch(error => console.error('Error:', error));
                }
            };

            // Vista previa de la imagen cargada
            imageInput.onchange = function() {
                const file = imageInput.files[0];
                const reader = new FileReader();
                reader.onload = function(e) {
                    imagePreview.src = e.target.result;
                    imagePreview.style.display = "block";
                };
                reader.readAsDataURL(file);
            };
            document.getElementById("download-button").onclick = function() {
            const chatBox = document.getElementById("chat-box");

            if (!chatBox || chatBox.children.length === 0) {
                alert("No hay conversaciones disponibles para descargar.");
                return;
            }

            const conversationText = Array.from(chatBox.children)
                .map(child => child.textContent.trim())
                .join("\n\n");

            // Verificar si hay texto para generar el PDF
            if (!conversationText) {
                alert("No hay contenido para generar el archivo PDF.");
                return;
            }

            try {
                const { jsPDF } = window.jspdf;
                const pdf = new jsPDF();

                const pageWidth = pdf.internal.pageSize.getWidth();
                const margin = 10;
                const maxLineWidth = pageWidth - margin * 2;

                pdf.setFont("Helvetica", "normal");
                pdf.setFontSize(12);

                const textLines = pdf.splitTextToSize(conversationText, maxLineWidth);
                pdf.text(textLines, margin, margin + 10);

                // Descargar el archivo
                pdf.save("conversation.pdf");
            } catch (error) {
                console.error("Error al generar el PDF:", error);
                alert("Ocurrió un error al generar el archivo PDF. Verifica la consola para más detalles.");
            }
        };


        });
    </script>

    <!-- Aquí agregamos el popup -->
    <div id="popup" class="popup hidden"></div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/loaders/GLTFLoader.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.2/gsap.min.js"></script>
    <script>
        let animations
        let mixer; // AnimationMixer
        let animationActions = {}; // Guardará las animaciones por nombre
        let activeAction; // Animación activa
        let animationpath;
        // Cargar el archivo GLB
        
        // Crear la escena y la cámara
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(65, 500 / 500, 0.1, 1000);
        camera.position.set(0, 3.1, 0.9); // Ajustamos la altura para estar a nivel de los ojos del avatar
        
        // Configurar el renderizador
        const renderer = new THREE.WebGLRenderer({ alpha: true, antialias: true });
        renderer.setSize(600, 500);
        document.getElementById("avatar-container").appendChild(renderer.domElement);
    
        // Añadir luces a la escena
        const ambientLight = new THREE.AmbientLight(0xffffff, 1.5);
        scene.add(ambientLight);
    
        const directionalLight = new THREE.DirectionalLight(0xffffff, 1.3);
        directionalLight.position.set(1, 1, 1).normalize();
        scene.add(directionalLight);
    
        // Obtener el parámetro 'domain' desde la URL
        const urlParams = new URLSearchParams(window.location.search);
        const domain = urlParams.get('domain');
    
        // Definir la ruta del modelo en función del dominio
        let modelPath;
        switch (domain) {
            case 'culinary':
                modelPath = '{{ url_for("static", filename="models/avatar1.glb") }}';
                animationpath = '{{ url_for("static", filename="animations/animationschef.glb") }}';
                break;
            case 'fashion':
                modelPath = '{{ url_for("static", filename="models/avatar3.glb") }}';
                animationpath = '{{ url_for("static", filename="animations/animationsfashion.glb") }}';
                break;
            case 'gym':
                modelPath = '{{ url_for("static", filename="models/avatar2.glb") }}';
                animationpath = '{{ url_for("static", filename="animations/animationsgym.glb") }}';
                break;
            default:
                console.error('Dominio no reconocido.');
        }
    
        // Cargar el modelo 3D seleccionado
        const loader = new THREE.GLTFLoader();
        let model;
    
        if (modelPath) {
    loader.load(modelPath, function(gltf) {
        model = gltf.scene;
        scene.add(model);
        model.traverse((child) => {
            if (child.isMesh && child.name === 'Wolf3D_Head') {
                jawOpenTarget = child.morphTargetDictionary['jawOpen'];

                // Establecer el valor de jawOpen al 1 por defecto
                if (jawOpenTarget !== undefined) {
                    child.morphTargetInfluences[jawOpenTarget] = 0; // 1 representa la apertura total de la mandíbula
                }
            }
            
        });
        loadAnimations()
        
        // Asegurarse de que el avatar esté mirando hacia la cámara
        model.rotation.y = 0;  // Asegura que el modelo esté mirando hacia la cámara desde el inicio
        model.rotation.x = 0;
    
        // Centrar el modelo en la escena (en el centro del div)
        model.position.set(0, 1.6, 0);  // Coloca el modelo en el origen (0, 0, 0)
        
        // Animar el modelo
        function animate() {
            requestAnimationFrame(animate);
            if (mixer) {

                mixer.update(0.01); // Actualizar el mixer
            }
            renderer.render(scene, camera);
        }
        animate();
        
    });

    function loadAnimations() {
    loader.load(
        animationpath,
        function (gltf) {
            animations = gltf.animations; // Extraer los clips de animación
            mixer = new THREE.AnimationMixer(model); // Vincular el mixer al avatar
            
            animations.forEach((clip) => {
                clip.tracks = clip.tracks.filter((track) => {
                    return !track.name.includes('position'); // Ignora canales de posición
                });
               
                const action = mixer.clipAction(clip);
                animationActions[clip.name] = action; // Guardar la acción por su nombre
            });
            playAnimationSequence("salute", "pose")
            
        },
        
        undefined,
        function (error) {
            console.error('Error al cargar las animaciones:', error);
        } 
    );   
    }
    function playAnimationSequence(firstAnimationName, secondAnimationName) {
    // Detener y desvanecer cualquier animación activa
    if (activeAction) {
        activeAction.fadeOut(0.5); // Transición suave al detener la animación actual
    }

    // Configurar la primera animación
    const firstAction = animationActions[firstAnimationName];
    firstAction.reset();
    firstAction.setLoop(THREE.LoopOnce); // Primera animación solo una vez
    firstAction.timeScale = 0.8 // Ajustar la velocidad de reproducción
    firstAction.clampWhenFinished = true; // Mantener el último fotograma

    // Configurar la segunda animación
    const secondAction = animationActions[secondAnimationName];
    secondAction.reset();
    secondAction.setLoop(THREE.LoopRepeat); // Segunda animación en bucle

    // Reproducir la primera animación
    activeAction = firstAction;
    firstAction.fadeIn(0.5).play();

    // Listener para cambiar a la segunda animación al finalizar la primera
    mixer.addEventListener('finished', (event) => {
        if (event.action === firstAction) {
            activeAction.fadeOut(0.8); // Desvanecer la primera animación
            activeAction = secondAction;
            secondAction.fadeIn(0.6).play(); // Activar la segunda animación
        }
    });
}

function playAnimationLoop(animationName, speed) {
    // Detener cualquier animación activa (incluidas las de playAnimationSequence)
    if (activeAction) {
        activeAction.fadeOut(0.5); // Transición suave al detener
    }

    // Configurar y reproducir la nueva animación
    const loopAction = animationActions[animationName];
    loopAction.reset();
    loopAction.setLoop(THREE.LoopRepeat); // Repetir en bucle
    loopAction.timeScale = speed; // Ajustar la velocidad de reproducción
    activeAction = loopAction;
    loopAction.fadeIn(0.5).play();
}
function playAnimationOnce(animationName) {
    if (activeAction) {
        activeAction.stop(); // Detener la animación activa actual
    }
    activeAction = animationActions[animationName];
    activeAction.reset();
    activeAction.fadeIn(1);
    activeAction.play(); // Reiniciar y reproducir la nueva animación
    activeAction.setLoop(THREE.LoopOnce, 1); // Asegurarse de que la animación se ejecute solo una vez
}

window.addEventListener('hablar', () => {
    dots.style.opacity = 0;
    playAnimationLoop("talking", 1);
});
window.addEventListener('pensar', () => {

    playAnimationLoop("thinking", 0.5);
});

window.addEventListener('parar', () => {
    playAnimationLoop("pose")
});

    window.addEventListener('audio-level', (event) => {
        const amplitude = event.detail.amplitude;
        if (jawOpenTarget !== null && model) {
            model.traverse((child) => {
                if (child.isMesh && child.name === 'Wolf3D_Head') {
                    child.morphTargetInfluences[jawOpenTarget] = amplitude;
                }
            });
        }
    });


// Función para realizar el parpadeo
function blink() {
    model.traverse((child) => {
        if (child.isMesh && child.name === 'Wolf3D_Head') {
  let blinkProgress = 0;
  let direction = 1; // 1 para cerrar el ojo, -1 para abrirlo
  const blinkSpeed = 0.1; // Velocidad del parpadeo
  
  function animateBlink() {
    blinkProgress += direction * blinkSpeed;
    if (blinkProgress >= 1) {
      direction = -1; // Cambiar dirección para abrir el ojo
    } else if (blinkProgress <= 0) {
      cancelAnimationFrame(animateBlinkId); // Finalizar la animación
      return;
    }
    // Actualizar los morphTargets
    child.morphTargetInfluences[child.morphTargetDictionary['eyeBlinkLeft']] = blinkProgress;
    child.morphTargetInfluences[child.morphTargetDictionary['eyeBlinkRight']] = blinkProgress;

    // Continuar la animación
    animateBlinkId = requestAnimationFrame(animateBlink);
  }

  let animateBlinkId = requestAnimationFrame(animateBlink);
        }
});
}

// Función para iniciar parpadeos aleatorios
function startRandomBlinks() {
  function scheduleNextBlink() {
    const randomDelay = Math.random() * 3000 + 2000; // Entre 2 y 5 segundos
    setTimeout(() => {
      blink();
      scheduleNextBlink(); // Planificar el siguiente parpadeo
    }, randomDelay);
  }

  scheduleNextBlink(); // Iniciar el primer parpadeo
}

// Iniciar parpadeos aleatorios
startRandomBlinks();
}





    
        // Variables para el control del mouse
        let isMouseDown = false;
        let previousMousePosition = { x: 0, y: 0 };
    
        // Detectar cuando el mouse se presiona
        document.addEventListener('mousedown', (event) => {
            isMouseDown = true;
            previousMousePosition.x = event.clientX;
            previousMousePosition.y = event.clientY;
        });
    
        // Detectar cuando el mouse se mueve mientras está presionado
        document.addEventListener('mousemove', (event) => {
            if (!isMouseDown || !model) return;
    
            const deltaX = event.clientX - previousMousePosition.x;
            model.rotation.y += deltaX * 0.01;
    
            previousMousePosition.x = event.clientX;
        });
    
        // Detectar cuando el mouse se libera
        document.addEventListener('mouseup', () => {
            isMouseDown = false;
        });
    </script>
 
    
</body>
</html>
