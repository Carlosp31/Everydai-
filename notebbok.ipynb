{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, scrolledtext\n",
    "from PIL import Image, ImageTk\n",
    "import speech_recognition as sr\n",
    "import google.generativeai as genai\n",
    "import cv2\n",
    "import numpy as np\n",
    "import threading\n",
    "import requests\n",
    "import pygame\n",
    "import os\n",
    "import serpapi\n",
    "\n",
    "# Inicializa el reconocimiento de voz\n",
    "reconocedor = sr.Recognizer()\n",
    "\n",
    "# Configura el modelo generativo\n",
    "model_img = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "name = \"domain4cookin\"\n",
    "model = genai.GenerativeModel(model_name=f'tunedModels/{name}')\n",
    "chat = model.start_chat(\n",
    "    history=[\n",
    "        {\"role\": \"user\", \"parts\": \"el modelo debe actuar como un profesor de culinaria. Recibe una lista de ingredientes y debe proporcionarle al usuario una lista de pasos y guiar al usuario para que efectúe la receta. Solo puede sugerir recetas con los ingredientes que recibe en la lista, únicamente esos.\"},\n",
    "        {\"role\": \"model\", \"parts\": \"Bien. Dime los ingredientes, y te sugiriré ingrientes, y te daré los pasos, de acuerdo a ellos. Solo los ingredientes que me digas\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "recording = False\n",
    "audio_thread = None\n",
    "SERPAPI_KEY= \"bb20458d63685c912702170baec0c6fe049a33fa70c5bf93c751ec93147a8f95\"\n",
    "client = serpapi.Client(api_key=SERPAPI_KEY)\n",
    "API_KEY = 'bb20458d63685c912702170baec0c6fe049a33fa70c5bf93c751ec93147a8f95'  # Reemplaza con tu API Key de Eleven Labs\n",
    "\n",
    "\n",
    "def sintetizar_voz(texto):\n",
    "    # Directorio temporal para guardar el archivo de audio\n",
    "    temp_dir = os.path.join(os.path.expanduser(\"~\"), \"AppData\", \"Local\", \"Temp\")\n",
    "    audio_path = os.path.join(temp_dir, \"respuesta_audio.mp3\")\n",
    "\n",
    "    # Si el archivo ya existe, elimínalo antes de escribir uno nuevo\n",
    "    if os.path.exists(audio_path):\n",
    "        os.remove(audio_path)\n",
    "\n",
    "    url = \"https://api.elevenlabs.io/v1/text-to-speech/9BWtsMINqrJLrRacOk9x\"  # Cambia YOUR_VOICE_ID por el ID de la voz que quieras usar\n",
    "    headers = {\n",
    "        'accept': 'audio/mpeg',\n",
    "        'xi-api-key': API_KEY,  # Asegúrate de reemplazar con tu API_KEY\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "    data = {\n",
    "        \"text\": texto,\n",
    "        \"model_id\": \"eleven_multilingual_v2\",\n",
    "        \"voice_settings\": {\n",
    "            \"stability\": 0.5,\n",
    "            \"similarity_boost\": 1\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Solicitud a la API para sintetizar la voz\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        # Guardar el archivo de audio en el directorio temporal\n",
    "        with open(audio_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        return audio_path\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def reproducir_audio(file):\n",
    "    pygame.mixer.init()  # Inicializa el mezclador de audio\n",
    "    pygame.mixer.music.load(file)  # Carga el archivo MP3\n",
    "    pygame.mixer.music.play()  # Reproduce el archivo\n",
    "\n",
    "    # Mantén el programa en ejecución hasta que el archivo de audio termine\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        pygame.time.Clock().tick(10)  # Pausa el bucle para evitar bloqueo\n",
    "\n",
    "    pygame.mixer.music.stop()  # Detener la reproducción\n",
    "    pygame.mixer.quit()  # Cierra el mixer y libera el archivo de audio\n",
    "\n",
    "\n",
    "def reproducir_audio_thread(file):\n",
    "    thread = threading.Thread(target=reproducir_audio, args=(file,))\n",
    "    thread.start()\n",
    "\n",
    "\n",
    "def reconocer_voz():\n",
    "    global recording\n",
    "    if not recording:\n",
    "        return\n",
    "\n",
    "    with sr.Microphone() as source:\n",
    "        reconocedor.energy_threshold = noise_slider.get()\n",
    "        reconocedor.adjust_for_ambient_noise(source, duration=1)\n",
    "        audio = reconocedor.listen(source)\n",
    "\n",
    "        try:\n",
    "            texto = reconocedor.recognize_google(audio, language=\"es-ES\")\n",
    "            return texto\n",
    "        except sr.UnknownValueError:\n",
    "            return \"Could not understand the audio\"\n",
    "        except sr.RequestError as e:\n",
    "            return f\"Error connecting to the speech recognition service; {e}\"\n",
    "\n",
    "\n",
    "def load_image():\n",
    "    file_path = filedialog.askopenfilename(\n",
    "        filetypes=[(\"Image files\", \"*.jpg;*.jpeg;*.png;*.bmp;*.gif\")],\n",
    "        title=\"Select an image\"\n",
    "    )\n",
    "\n",
    "    if file_path:\n",
    "        image = Image.open(file_path)\n",
    "        return image\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def capture_from_camera():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        return None\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if ret:\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(frame_rgb)\n",
    "        return image\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def send_message():\n",
    "    texto = input_text.get(\"1.0\", \"end-1c\")\n",
    "    if not texto:\n",
    "        return\n",
    "\n",
    "    # Envía el mensaje al modelo\n",
    "    response = chat.send_message(\n",
    "        texto,\n",
    "        generation_config=genai.types.GenerationConfig(\n",
    "            candidate_count=1,\n",
    "            stop_sequences=[\"x\"],\n",
    "            max_output_tokens=50,\n",
    "            temperature=0.7\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    respuesta_texto = response.text\n",
    "    \n",
    "    # Mostrar la respuesta del modelo en el chat\n",
    "    chat_history.insert(tk.END, f\"You: {texto}\\n\")\n",
    "    chat_history.insert(tk.END, f\"Model: {respuesta_texto}\\n\")\n",
    "    input_text.delete(\"1.0\", tk.END)\n",
    "\n",
    "    # Obtener recetas de SerpAPI basadas en los ingredientes\n",
    "    recetas = buscar_recetas_en_serpapi(texto)\n",
    "    if recetas:\n",
    "        chat_history.insert(tk.END, f\"Recetas relacionadas:\\n\")\n",
    "        for receta in recetas:\n",
    "            chat_history.insert(tk.END, f\"- {receta['title']}: {receta['link']}\\n\")\n",
    "    \n",
    "    # Generar y reproducir el audio con Eleven Labs\n",
    "    archivo_audio = sintetizar_voz(respuesta_texto)\n",
    "    if archivo_audio:\n",
    "        reproducir_audio_thread(archivo_audio)\n",
    "def buscar_recetas_en_serpapi(ingredientes):\n",
    "    try:\n",
    "        result = client.search(\n",
    "            q=f\"Recetas con {ingredientes}\",\n",
    "            engine=\"google\",\n",
    "            hl=\"es\",\n",
    "            gl=\"co\"\n",
    "        )\n",
    "        return result.get(\"recipes_results\", [])\n",
    "    except Exception as e:\n",
    "        chat_history.insert(tk.END, f\"Error al buscar en SerpAPI: {e}\\n\")\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "def handle_audio():\n",
    "    global audio_thread\n",
    "    audio_thread = threading.Thread(target=lambda: process_audio())\n",
    "    audio_thread.start()\n",
    "\n",
    "\n",
    "def process_audio():\n",
    "    global recording\n",
    "    recording = True\n",
    "    texto = reconocer_voz()\n",
    "    if texto:\n",
    "        input_text.delete(\"1.0\", tk.END)\n",
    "        input_text.insert(tk.END, texto)\n",
    "        send_message()\n",
    "    recording = False\n",
    "\n",
    "\n",
    "def handle_image(image):\n",
    "    if image:\n",
    "        try:\n",
    "            response = model_img.generate_content(\n",
    "                [\"Act as a culinary master and identify each ingredient you see in the image in detail. Be concise and just print the ingredient list. Do something like: The ingredients: (and insert the list)\", image],\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    candidate_count=1,\n",
    "                    stop_sequences=[\"x\"],\n",
    "                    max_output_tokens=50,\n",
    "                    temperature=0.7\n",
    "                )\n",
    "            )\n",
    "            chat_history.insert(tk.END, f\"You: Image loaded\\n\")\n",
    "            chat_history.insert(tk.END, f\"Model: {response.text}\\n\")\n",
    "        except Exception as e:\n",
    "            chat_history.insert(tk.END, f\"Error processing the image: {e}\\n\")\n",
    "\n",
    "\n",
    "def on_send_click():\n",
    "    send_message()\n",
    "\n",
    "\n",
    "def on_audio_button_press(event):\n",
    "    handle_audio()\n",
    "\n",
    "\n",
    "def on_audio_button_release(event):\n",
    "    global recording\n",
    "    recording = False\n",
    "\n",
    "\n",
    "def on_image_click():\n",
    "    image = load_image()\n",
    "    if image:\n",
    "        handle_image(image)\n",
    "        img_tk = ImageTk.PhotoImage(image)\n",
    "        image_label.config(image=img_tk)\n",
    "        image_label.image = img_tk\n",
    "\n",
    "\n",
    "def on_camera_click():\n",
    "    image = capture_from_camera()\n",
    "    if image:\n",
    "        handle_image(image)\n",
    "        img_tk = ImageTk.PhotoImage(image)\n",
    "        camera_label.config(image=img_tk)\n",
    "        camera_label.image = img_tk\n",
    "\n",
    "\n",
    "def on_clear_click():\n",
    "    chat_history.delete(1.0, tk.END)\n",
    "    image_label.config(image='')\n",
    "    camera_label.config(image='')\n",
    "\n",
    "\n",
    "# Configura la ventana de la interfaz gráfica\n",
    "root = tk.Tk()\n",
    "root.title(\"Chat with Culinary Model\")\n",
    "\n",
    "main_frame = tk.Frame(root, padx=10, pady=10)\n",
    "main_frame.pack(expand=True, fill=tk.BOTH)\n",
    "\n",
    "left_frame = tk.Frame(main_frame, padx=10, pady=10)\n",
    "left_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "right_frame = tk.Frame(main_frame, padx=10, pady=10)\n",
    "right_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "title_label = tk.Label(right_frame, text=\"Chat with Culinary Model\", font=(\"Helvetica\", 16, \"bold\"))\n",
    "title_label.pack(pady=5)\n",
    "\n",
    "chat_history = scrolledtext.ScrolledText(right_frame, wrap=tk.WORD, height=15, width=40)\n",
    "chat_history.pack(pady=10, fill=tk.BOTH, expand=True)\n",
    "\n",
    "input_text = tk.Text(right_frame, height=3, width=40)\n",
    "input_text.pack(pady=5, fill=tk.BOTH, expand=True)\n",
    "\n",
    "slider_frame = tk.Frame(right_frame, pady=10)\n",
    "slider_frame.pack(fill=tk.X)\n",
    "\n",
    "slider_label = tk.Label(slider_frame, text=\"Noise Sensitivity:\")\n",
    "slider_label.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "noise_slider = tk.Scale(slider_frame, from_=100, to=10000, orient=tk.HORIZONTAL)\n",
    "noise_slider.set(reconocedor.energy_threshold)\n",
    "noise_slider.pack(side=tk.LEFT, padx=5, fill=tk.X, expand=True)\n",
    "\n",
    "button_frame = tk.Frame(right_frame)\n",
    "button_frame.pack(pady=10)\n",
    "\n",
    "send_button = tk.Button(button_frame, text=\"Send\", command=on_send_click, width=15)\n",
    "send_button.grid(row=0, column=0, padx=5)\n",
    "\n",
    "audio_button = tk.Button(button_frame, text=\"Voice Recognition\", width=20)\n",
    "audio_button.grid(row=0, column=1, padx=5)\n",
    "audio_button.bind(\"<ButtonPress>\", on_audio_button_press)\n",
    "audio_button.bind(\"<ButtonRelease>\", on_audio_button_release)\n",
    "\n",
    "image_button = tk.Button(button_frame, text=\"Load Image\", command=on_image_click, width=15)\n",
    "image_button.grid(row=0, column=2, padx=5)\n",
    "\n",
    "camera_button = tk.Button(button_frame, text=\"Capture Camera\", command=on_camera_click, width=15)\n",
    "camera_button.grid(row=0, column=3, padx=5)\n",
    "\n",
    "clear_button = tk.Button(button_frame, text=\"Clear\", command=on_clear_click, width=15)\n",
    "clear_button.grid(row=0, column=4, padx=5)\n",
    "\n",
    "image_label = tk.Label(left_frame)\n",
    "image_label.pack(pady=10)\n",
    "\n",
    "camera_label = tk.Label(left_frame)\n",
    "camera_label.pack(pady=10)\n",
    "\n",
    "# Inicia el bucle principal\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
